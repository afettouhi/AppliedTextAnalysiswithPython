{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "# In a custom corpus reader class\n",
    "def manifest(self):\n",
    "    \"\"\"\n",
    "    Reads and parses the manifest.json file in our corpus if it exists.\n",
    "    \"\"\"\n",
    "    return json.load(self.open(\"README.md\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: '/path/to/corpus/root'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-82c448c1c840>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mCAT_PATTERN\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mr'([\\w_\\s]+)/.*'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m corpus = CategorizedPlaintextCorpusReader(\n\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0;34m'/path/to/corpus/root'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDOC_PATTERN\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcat_pattern\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mCAT_PATTERN\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m )\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/AppliedTextAnalysiswithPython/lib/python3.8/site-packages/nltk/corpus/reader/plaintext.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    172\u001B[0m         \"\"\"\n\u001B[1;32m    173\u001B[0m         \u001B[0mCategorizedCorpusReader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 174\u001B[0;31m         \u001B[0mPlaintextCorpusReader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    175\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    176\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_resolve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfileids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcategories\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/AppliedTextAnalysiswithPython/lib/python3.8/site-packages/nltk/corpus/reader/plaintext.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, fileids, word_tokenizer, sent_tokenizer, para_block_reader, encoding)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mcorpus\u001B[0m \u001B[0minto\u001B[0m \u001B[0mparagraph\u001B[0m \u001B[0mblocks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         \"\"\"\n\u001B[0;32m---> 63\u001B[0;31m         \u001B[0mCorpusReader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfileids\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_word_tokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mword_tokenizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sent_tokenizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msent_tokenizer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/AppliedTextAnalysiswithPython/lib/python3.8/site-packages/nltk/corpus/reader/api.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, fileids, encoding, tagset)\u001B[0m\n\u001B[1;32m     78\u001B[0m                 \u001B[0mroot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mZipFilePathPointer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mzipfile\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mzipentry\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     79\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 80\u001B[0;31m                 \u001B[0mroot\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFileSystemPathPointer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     81\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPathPointer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     82\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"CorpusReader: expected a string or a PathPointer\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/AppliedTextAnalysiswithPython/lib/python3.8/site-packages/nltk/compat.py\u001B[0m in \u001B[0;36m_decorator\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     39\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_decorator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0margs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0madd_py3_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0minit_func\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minit_func\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_decorator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Dokumenter/Programs/miniconda3/envs/AppliedTextAnalysiswithPython/lib/python3.8/site-packages/nltk/data.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, _path)\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0m_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mabspath\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    314\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexists\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 315\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mIOError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"No such file or directory: %r\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0m_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    316\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_path\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mOSError\u001B[0m: No such file or directory: '/path/to/corpus/root'"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader.plaintext import CategorizedPlaintextCorpusReader\n",
    "\n",
    "DOC_PATTERN = r'(?!\\.)[\\w_\\s]+/[\\w\\s\\d\\-]+\\.txt'\n",
    "CAT_PATTERN = r'([\\w_\\s]+)/.*'\n",
    "\n",
    "corpus = CategorizedPlaintextCorpusReader(\n",
    "    '../data/', DOC_PATTERN, cat_pattern=CAT_PATTERN\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-cd5fc98e137e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mcorpus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcategories\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;31m# ['Star Trek', 'Star Wars']\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mcorpus\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfileids\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m# ['Star Trek/Star Trek - Balance of Terror.txt',\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "corpus.categories()\n",
    "# ['Star Trek', 'Star Wars']\n",
    "\n",
    "corpus.fileids()\n",
    "# ['Star Trek/Star Trek - Balance of Terror.txt',\n",
    "#  'Star Trek/Star Trek - First Contact.txt', ...]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from nltk.corpus.reader.api import CorpusReader\n",
    "from nltk.corpus.reader.api import CategorizedCorpusReader\n",
    "\n",
    "CAT_PATTERN = r'([a-z_\\s]+)/.*'\n",
    "DOC_PATTERN = r'(?!\\.)[a-z_\\s]+/[a-f0-9]+\\.json'\n",
    "TAGS = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'h7', 'p', 'li']\n",
    "\n",
    "class HTMLCorpusReader(CategorizedCorpusReader, CorpusReader):\n",
    "    \"\"\"\n",
    "    A corpus reader for raw HTML documents to enable preprocessing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, fileids=DOC_PATTERN, encoding='utf8',\n",
    "                 tags=TAGS, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the corpus reader.  Categorization arguments\n",
    "        (``cat_pattern``, ``cat_map``, and ``cat_file``) are passed to\n",
    "        the ``CategorizedCorpusReader`` constructor.  The remaining\n",
    "        arguments are passed to the ``CorpusReader`` constructor.\n",
    "        \"\"\"\n",
    "        # Add the default category pattern if not passed into the class.\n",
    "        if not any(key.startswith('cat_') for key in kwargs.keys()):\n",
    "            kwargs['cat_pattern'] = CAT_PATTERN\n",
    "\n",
    "        # Initialize the NLTK corpus reader objects\n",
    "        CategorizedCorpusReader.__init__(self, kwargs)\n",
    "        CorpusReader.__init__(self, root, fileids, encoding)\n",
    "\n",
    "        # Save the tags that we specifically want to extract.\n",
    "        self.tags = tags"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "    def resolve(self, fileids, categories):\n",
    "        \"\"\"\n",
    "        Returns a list of fileids or categories depending on what is passed\n",
    "        to each internal corpus reader function. Implemented similarly to\n",
    "        the NLTK ``CategorizedPlaintextCorpusReader``.\n",
    "        \"\"\"\n",
    "        if fileids is not None and categories is not None:\n",
    "            raise ValueError(\"Specify fileids or categories, not both\")\n",
    "\n",
    "        if categories is not None:\n",
    "            return self.fileids(categories)\n",
    "        return fileids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def docs(self, fileids=None, categories=None):\n",
    "    \"\"\"\n",
    "    Returns the complete text of an HTML document, closing the document\n",
    "    after we are done reading it and yielding it in a memory safe fashion.\n",
    "    \"\"\"\n",
    "    # Resolve the fileids and the categories\n",
    "    fileids = self.resolve(fileids, categories)\n",
    "\n",
    "    # Create a generator, loading one document into memory at a time.\n",
    "    for path, encoding in self.abspaths(fileids, include_encoding=True):\n",
    "        with codecs.open(path, 'r', encoding=encoding) as f:\n",
    "            yield f.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def sizes(self, fileids=None, categories=None):\n",
    "    \"\"\"\n",
    "    Returns a list of tuples, the fileid and size on disk of the file.\n",
    "    This function is used to detect oddly large files in the corpus.\n",
    "    \"\"\"\n",
    "    # Resolve the fileids and the categories\n",
    "    fileids = self.resolve(fileids, categories)\n",
    "\n",
    "    # Create a generator, getting every path and computing filesize\n",
    "    for path in self.abspaths(fileids):\n",
    "        yield os.path.getsize(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "class SqliteCorpusReader(object):\n",
    "\n",
    "    def __init__(self, path):\n",
    "        self._cur = sqlite3.connect(path).cursor()\n",
    "\n",
    "    def ids(self):\n",
    "        \"\"\"\n",
    "        Returns the review ids, which enable joins to other\n",
    "        review metadata\n",
    "        \"\"\"\n",
    "        self._cur.execute(\"SELECT reviewid FROM content\")\n",
    "        for idx in iter(self._cur.fetchone, None):\n",
    "            yield idx\n",
    "\n",
    "    def scores(self):\n",
    "        \"\"\"\n",
    "        Returns the review score, to be used as the target\n",
    "        for later supervised learning problems\n",
    "        \"\"\"\n",
    "        self._cur.execute(\"SELECT score FROM reviews\")\n",
    "        for score in iter(self._cur.fetchone, None):\n",
    "            yield score\n",
    "\n",
    "    def texts(self):\n",
    "        \"\"\"\n",
    "        Returns the full review texts, to be preprocessed and\n",
    "        vectorized for supervised learning\n",
    "        \"\"\"\n",
    "        self._cur.execute(\"SELECT content FROM content\")\n",
    "        for text in iter(self._cur.fetchone, None):\n",
    "            yield text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}